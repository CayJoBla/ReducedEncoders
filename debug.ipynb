{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from reduced_encoders import (\n",
    "    BertReducedConfig,                          # PASS\n",
    "    MPNetReducedConfig,                         # PASS\n",
    "    DimReshape,                                 # PASS\n",
    "    DimReduce,                                  # PASS\n",
    "    DimExpand,                                  # PASS\n",
    "    BertReducedModel,                           # PASS\n",
    "    BertReducedForPreTraining,                  # PASS\n",
    "    BertReducedForSequenceClassification,       # PASS\n",
    "    MPNetReducedModel,                          # PASS\n",
    "    MPNetReducedForSequenceClassification,      # PASS\n",
    "    MPNetCompressedModel,                       # PASS\n",
    "    MPNetCompressedForPreTraining,              # PASS\n",
    "    MPNetCompressedForSequenceClassification,   # PASS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"This is a test sentence to pass through my models\",\n",
    "        \"This is a second test sentence to pass through my models that is similar\",\n",
    "        \"The quick brown fox jumped over the lazy dog\",] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cayjobla/miniconda3/envs/reduced_encoders/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_inputs = bert_tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "bert_inputs = {key:value.to(device) for key, value in bert_inputs.items()}\n",
    "bert_inputs['output_hidden_states'] = True\n",
    "bert_inputs['output_attentions'] = True\n",
    "bert_labels = torch.tensor([0, 1, 0]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpnet_tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "mpnet_inputs = mpnet_tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "mpnet_inputs = {key:value.to(device) for key, value in mpnet_inputs.items()}\n",
    "mpnet_inputs['output_hidden_states'] = True\n",
    "mpnet_inputs['output_attentions'] = True\n",
    "mpnet_labels = torch.tensor([0, 1, 0]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertReducedConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert_reduced\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"reduced_size\": 48,\n",
       "  \"reduction_sizes\": [\n",
       "    512,\n",
       "    256,\n",
       "    128,\n",
       "    68,\n",
       "    48\n",
       "  ],\n",
       "  \"transformers_version\": \"4.40.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PASS(1/2): No errors\n",
    "bert_config = BertReducedConfig()\n",
    "bert_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPNetReducedConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"mpnet_reduced\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"pooling_mode\": \"mean\",\n",
       "  \"reduced_size\": 48,\n",
       "  \"reduction_sizes\": [\n",
       "    512,\n",
       "    256,\n",
       "    128,\n",
       "    68,\n",
       "    48\n",
       "  ],\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"transformers_version\": \"4.40.2\",\n",
       "  \"vocab_size\": 30527\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PASS(2/2): No errors\n",
    "mpnet_config = MPNetReducedConfig()\n",
    "mpnet_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertReducedConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"hidden_act\": \"relu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert_reduced\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"reduced_size\": 32,\n",
       "  \"reduction_sizes\": [\n",
       "    256,\n",
       "    64,\n",
       "    32\n",
       "  ],\n",
       "  \"transformers_version\": \"4.40.2\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PASS(1/2): No errors, and custom variables were correctly set\n",
    "BertReducedConfig(reduction_sizes=[256, 64, 32], hidden_act=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPNetReducedConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"relu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"mpnet_reduced\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"pooling_mode\": \"cls\",\n",
       "  \"reduced_size\": 32,\n",
       "  \"reduction_sizes\": [\n",
       "    256,\n",
       "    64,\n",
       "    32\n",
       "  ],\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"transformers_version\": \"4.40.2\",\n",
       "  \"vocab_size\": 30527\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PASS(2/2): No errors, and custom variables were correctly set\n",
    "MPNetReducedConfig(reduction_sizes=[256, 64, 32], hidden_act=\"relu\", pooling_mode=\"cls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test DimReshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DimReshape(\n",
       "  (layernorm): LayerNorm((100,), eps=1e-12, elementwise_affine=True)\n",
       "  (activation): GELUActivation()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (dense): Linear(in_features=100, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PASS(1/2): Module initialized without error\n",
    "reshape_down = DimReshape(100, 5, bert_config)\n",
    "reshape_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DimReshape(\n",
       "  (layernorm): LayerNorm((5,), eps=1e-12, elementwise_affine=True)\n",
       "  (activation): GELUActivation()\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (dense): Linear(in_features=5, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PASS(2/2): Module initialized without error\n",
    "reshape_up = DimReshape(5, 100, mpnet_config)   # Try with different config\n",
    "reshape_up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PASS(1/2): No errors, and output shape is correct\n",
    "reshape_down(torch.randn(3,100)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 100])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PASS(2/2): No errors, and output shape is correct\n",
    "reshape_up(torch.randn(3,5)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test DimReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DimReduce(\n",
       "  (0): DimReshape(\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (dense): Linear(in_features=768, out_features=512, bias=True)\n",
       "  )\n",
       "  (1): DimReshape(\n",
       "    (layernorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (dense): Linear(in_features=512, out_features=256, bias=True)\n",
       "  )\n",
       "  (2): DimReshape(\n",
       "    (layernorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "  )\n",
       "  (3): DimReshape(\n",
       "    (layernorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (dense): Linear(in_features=128, out_features=68, bias=True)\n",
       "  )\n",
       "  (4): DimReshape(\n",
       "    (layernorm): LayerNorm((68,), eps=1e-12, elementwise_affine=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (dense): Linear(in_features=68, out_features=48, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PASS (1/2): Module initialized without error, and structure looks correct\n",
    "reduce = DimReduce(config=bert_config)\n",
    "reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DimReduce(\n",
       "  (0): DimReshape(\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (dense): Linear(in_features=768, out_features=512, bias=True)\n",
       "  )\n",
       "  (1): DimReshape(\n",
       "    (layernorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (dense): Linear(in_features=512, out_features=256, bias=True)\n",
       "  )\n",
       "  (2): DimReshape(\n",
       "    (layernorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "  )\n",
       "  (3): DimReshape(\n",
       "    (layernorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (dense): Linear(in_features=128, out_features=68, bias=True)\n",
       "  )\n",
       "  (4): DimReshape(\n",
       "    (layernorm): LayerNorm((68,), eps=1e-12, elementwise_affine=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (dense): Linear(in_features=68, out_features=48, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PASS (2/2): Module initialized without error, and structure looks correct\n",
    "reduce = DimReduce(config=mpnet_config)     # Try with different config\n",
    "reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Reduced Embedding shape: torch.Size([3, 48])\n",
      "All Embedding shapes: [torch.Size([3, 512]), torch.Size([3, 256]), torch.Size([3, 128]), torch.Size([3, 68]), torch.Size([3, 48])]\n",
      "Number of Reductions: 5\n"
     ]
    }
   ],
   "source": [
    "# PASS: The output keys are correct, and all of the reduction shapes are as expected\n",
    "with torch.no_grad():\n",
    "    output = reduce(torch.randn(3,768))\n",
    "    print(\"Final Reduced Embedding shape:\", output[-1].shape)\n",
    "    print(\"All Embedding shapes:\", [layer.shape for layer in output])\n",
    "    print(\"Number of Reductions:\", len(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test DimExpand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DimExpand(\n",
       "  (0): DimReshape(\n",
       "    (layernorm): LayerNorm((48,), eps=1e-12, elementwise_affine=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (dense): Linear(in_features=48, out_features=68, bias=True)\n",
       "  )\n",
       "  (1): DimReshape(\n",
       "    (layernorm): LayerNorm((68,), eps=1e-12, elementwise_affine=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (dense): Linear(in_features=68, out_features=128, bias=True)\n",
       "  )\n",
       "  (2): DimReshape(\n",
       "    (layernorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (dense): Linear(in_features=128, out_features=256, bias=True)\n",
       "  )\n",
       "  (3): DimReshape(\n",
       "    (layernorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (dense): Linear(in_features=256, out_features=512, bias=True)\n",
       "  )\n",
       "  (4): DimReshape(\n",
       "    (layernorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (dense): Linear(in_features=512, out_features=768, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PASS (1/2): Module initialized without error, and structure looks correct\n",
    "expand = DimExpand(config=mpnet_config)\n",
    "expand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DimExpand(\n",
       "  (0): DimReshape(\n",
       "    (layernorm): LayerNorm((48,), eps=1e-12, elementwise_affine=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (dense): Linear(in_features=48, out_features=68, bias=True)\n",
       "  )\n",
       "  (1): DimReshape(\n",
       "    (layernorm): LayerNorm((68,), eps=1e-12, elementwise_affine=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (dense): Linear(in_features=68, out_features=128, bias=True)\n",
       "  )\n",
       "  (2): DimReshape(\n",
       "    (layernorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (dense): Linear(in_features=128, out_features=256, bias=True)\n",
       "  )\n",
       "  (3): DimReshape(\n",
       "    (layernorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (dense): Linear(in_features=256, out_features=512, bias=True)\n",
       "  )\n",
       "  (4): DimReshape(\n",
       "    (layernorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "    (activation): GELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (dense): Linear(in_features=512, out_features=768, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PASS (2/2): Module initialized without error, and structure looks correct\n",
    "expand = DimExpand(config=bert_config)\n",
    "expand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Reduced Embedding shape: torch.Size([3, 768])\n",
      "All Embedding shapes: [torch.Size([3, 68]), torch.Size([3, 128]), torch.Size([3, 256]), torch.Size([3, 512]), torch.Size([3, 768])]\n",
      "Number of Expansion: 5\n"
     ]
    }
   ],
   "source": [
    "# PASS: The output keys are correct, and all of the reduction shapes are as expected\n",
    "with torch.no_grad():\n",
    "    output = expand(torch.randn(3,48))\n",
    "    print(\"Final Reduced Embedding shape:\", output[-1].shape)\n",
    "    print(\"All Embedding shapes:\", [layer.shape for layer in output])\n",
    "    print(\"Number of Expansion:\", len(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test BertReducedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertReducedModel(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (reduce): DimReduce(\n",
       "    (0): DimReshape(\n",
       "      (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=768, out_features=512, bias=True)\n",
       "    )\n",
       "    (1): DimReshape(\n",
       "      (layernorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=512, out_features=256, bias=True)\n",
       "    )\n",
       "    (2): DimReshape(\n",
       "      (layernorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "    (3): DimReshape(\n",
       "      (layernorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=128, out_features=68, bias=True)\n",
       "    )\n",
       "    (4): DimReshape(\n",
       "      (layernorm): LayerNorm((68,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=68, out_features=48, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PASS: Module initialized without error\n",
    "config = BertReducedConfig()\n",
    "model = BertReducedModel(config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output keys: dict_keys(['last_reduced_hidden_state', 'last_full_hidden_state', 'reduced_pooler_output', 'full_pooler_output', 'reduced_hidden_states', 'full_hidden_states', 'past_key_values', 'attentions', 'cross_attentions'])\n",
      "Reduced Embedding shape: torch.Size([3, 16, 48])\n",
      "Full Embedding shape: torch.Size([3, 16, 768])\n",
      "Reduced Pooled shape: torch.Size([3, 48])\n",
      "Full Pooled shape: torch.Size([3, 768])\n",
      "Intermediate Embedding shapes: [torch.Size([3, 16, 512]), torch.Size([3, 16, 256]), torch.Size([3, 16, 128]), torch.Size([3, 16, 68]), torch.Size([3, 16, 48])]\n",
      "Intermediate Pooled shapes: [torch.Size([3, 512]), torch.Size([3, 256]), torch.Size([3, 128]), torch.Size([3, 68]), torch.Size([3, 48])]\n",
      "Included hidden states and attentions: True\n"
     ]
    }
   ],
   "source": [
    "# PASS: Inputs were passed through the model, and the output shapes are as expected\n",
    "with torch.no_grad():\n",
    "    outputs = model(**bert_inputs)\n",
    "    print(\"Output keys:\", outputs.__dict__.keys())\n",
    "    print(\"Reduced Embedding shape:\", outputs.last_reduced_hidden_state.shape)\n",
    "    print(\"Full Embedding shape:\", outputs.last_full_hidden_state.shape)\n",
    "    print(\"Reduced Pooled shape:\", outputs.reduced_pooler_output.shape)\n",
    "    print(\"Full Pooled shape:\", outputs.full_pooler_output.shape)\n",
    "    print(\"Intermediate Embedding shapes:\", [layer.shape for layer in outputs.reduced_hidden_states[0]])\n",
    "    print(\"Intermediate Pooled shapes:\", [layer.shape for layer in outputs.reduced_hidden_states[1]])\n",
    "    print(\"Included hidden states and attentions:\", bool(outputs.full_hidden_states and outputs.attentions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test BertReducedForPreTraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertReducedForPreTraining(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (reduce): DimReduce(\n",
       "    (0): DimReshape(\n",
       "      (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=768, out_features=512, bias=True)\n",
       "    )\n",
       "    (1): DimReshape(\n",
       "      (layernorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=512, out_features=256, bias=True)\n",
       "    )\n",
       "    (2): DimReshape(\n",
       "      (layernorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "    (3): DimReshape(\n",
       "      (layernorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=128, out_features=68, bias=True)\n",
       "    )\n",
       "    (4): DimReshape(\n",
       "      (layernorm): LayerNorm((68,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=68, out_features=48, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((48,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (cls): BertReducedPreTrainingHeads(\n",
       "    (predictions): BertReducedLMPredictionHead(\n",
       "      (transform): BertReducedPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=48, out_features=48, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((48,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=48, out_features=30522, bias=True)\n",
       "    )\n",
       "    (seq_relationship): Linear(in_features=48, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PASS: Module initialized without error and the structure looks correct\n",
    "config = BertReducedConfig()\n",
    "model = BertReducedForPreTraining(config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output keys: dict_keys(['loss', 'prediction_logits', 'seq_relationship_logits', 'reduced_hidden_states', 'full_hidden_states', 'attentions'])\n",
      "Loss (Should be None): None\n",
      "MLM logits shape: torch.Size([3, 16, 30522])\n",
      "Sequence logits: torch.Size([3, 2])\n",
      "Intermediate Embedding shapes: [torch.Size([3, 16, 512]), torch.Size([3, 16, 256]), torch.Size([3, 16, 128]), torch.Size([3, 16, 68]), torch.Size([3, 16, 48])]\n",
      "Intermediate Pooled shapes: [torch.Size([3, 512]), torch.Size([3, 256]), torch.Size([3, 128]), torch.Size([3, 68]), torch.Size([3, 48])]\n",
      "Included hidden states and attentions: True\n"
     ]
    }
   ],
   "source": [
    "# PASS(1/2): Inputs were passed through the model, and the output shapes are as expected\n",
    "with torch.no_grad():\n",
    "    outputs = model(**bert_inputs)\n",
    "    print(\"Output keys:\", outputs.__dict__.keys())\n",
    "    print(\"Loss (Should be None):\", outputs.loss)\n",
    "    print(\"MLM logits shape:\", outputs.prediction_logits.shape)\n",
    "    print(\"Sequence logits:\", outputs.seq_relationship_logits.shape)\n",
    "    print(\"Intermediate Embedding shapes:\", [layer.shape for layer in outputs.reduced_hidden_states[0]])\n",
    "    print(\"Intermediate Pooled shapes:\", [layer.shape for layer in outputs.reduced_hidden_states[1]])\n",
    "    print(\"Included hidden states and attentions:\", bool(outputs.full_hidden_states and outputs.attentions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output keys: dict_keys(['loss', 'prediction_logits', 'seq_relationship_logits', 'reduced_hidden_states', 'full_hidden_states', 'attentions'])\n",
      "Loss: tensor(11.1383, device='cuda:0')\n",
      "MLM logits shape: torch.Size([3, 16, 30522])\n",
      "Sequence logits: torch.Size([3, 2])\n",
      "Intermediate Embedding shapes: [torch.Size([3, 16, 512]), torch.Size([3, 16, 256]), torch.Size([3, 16, 128]), torch.Size([3, 16, 68]), torch.Size([3, 16, 48])]\n",
      "Intermediate Pooled shapes: [torch.Size([3, 512]), torch.Size([3, 256]), torch.Size([3, 128]), torch.Size([3, 68]), torch.Size([3, 48])]\n",
      "Included hidden states and attentions: True\n"
     ]
    }
   ],
   "source": [
    "# PASS(2/2): The full loss is computed without raising an error\n",
    "with torch.no_grad():\n",
    "    outputs = model(**bert_inputs, labels=bert_inputs['input_ids'], next_sentence_label=bert_labels)\n",
    "    print(\"Output keys:\", outputs.__dict__.keys())\n",
    "    print(\"Loss:\", outputs.loss)\n",
    "    print(\"MLM logits shape:\", outputs.prediction_logits.shape)\n",
    "    print(\"Sequence logits:\", outputs.seq_relationship_logits.shape)\n",
    "    print(\"Intermediate Embedding shapes:\", [layer.shape for layer in outputs.reduced_hidden_states[0]])\n",
    "    print(\"Intermediate Pooled shapes:\", [layer.shape for layer in outputs.reduced_hidden_states[1]])\n",
    "    print(\"Included hidden states and attentions:\", bool(outputs.full_hidden_states and outputs.attentions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test BertReducedForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertReducedForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (reduce): DimReduce(\n",
       "    (0): DimReshape(\n",
       "      (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=768, out_features=512, bias=True)\n",
       "    )\n",
       "    (1): DimReshape(\n",
       "      (layernorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=512, out_features=256, bias=True)\n",
       "    )\n",
       "    (2): DimReshape(\n",
       "      (layernorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "    (3): DimReshape(\n",
       "      (layernorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=128, out_features=68, bias=True)\n",
       "    )\n",
       "    (4): DimReshape(\n",
       "      (layernorm): LayerNorm((68,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=68, out_features=48, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((48,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=48, out_features=2, bias=True)\n",
       "  (seq_class_loss): SequenceClassificationLoss()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PASS: Module initialized without error\n",
    "config = BertReducedConfig()\n",
    "model = BertReducedForSequenceClassification(config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output keys: dict_keys(['loss', 'logits', 'reduced_hidden_states', 'full_hidden_states', 'attentions'])\n",
      "Loss (Should be None): None\n",
      "Logits shape: torch.Size([3, 2])\n",
      "Intermediate Pooled shapes: [torch.Size([3, 512]), torch.Size([3, 256]), torch.Size([3, 128]), torch.Size([3, 68]), torch.Size([3, 48])]\n",
      "Included hidden states and attentions: True\n"
     ]
    }
   ],
   "source": [
    "# PASS(1/2): Inputs were passed through the model, and the output shapes are as expected\n",
    "with torch.no_grad():\n",
    "    outputs = model(**bert_inputs)\n",
    "    print(\"Output keys:\", outputs.__dict__.keys())\n",
    "    print(\"Loss (Should be None):\", outputs.loss)\n",
    "    print(\"Logits shape:\", outputs.logits.shape)\n",
    "    print(\"Intermediate Pooled shapes:\", [layer.shape for layer in outputs.reduced_hidden_states])\n",
    "    print(\"Included hidden states and attentions:\", bool(outputs.full_hidden_states and outputs.attentions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output keys: dict_keys(['loss', 'logits', 'reduced_hidden_states', 'full_hidden_states', 'attentions'])\n",
      "Loss: tensor(0.7110, device='cuda:0')\n",
      "Logits shape: torch.Size([3, 2])\n",
      "Intermediate Pooled shapes: [torch.Size([3, 512]), torch.Size([3, 256]), torch.Size([3, 128]), torch.Size([3, 68]), torch.Size([3, 48])]\n",
      "Included hidden states and attentions: True\n"
     ]
    }
   ],
   "source": [
    "# PASS(2/2): Loss is computed without raising an error\n",
    "with torch.no_grad():\n",
    "    outputs = model(**bert_inputs, labels=bert_labels)\n",
    "    print(\"Output keys:\", outputs.__dict__.keys())\n",
    "    print(\"Loss:\", outputs.loss)\n",
    "    print(\"Logits shape:\", outputs.logits.shape)\n",
    "    print(\"Intermediate Pooled shapes:\", [layer.shape for layer in outputs.reduced_hidden_states])\n",
    "    print(\"Included hidden states and attentions:\", bool(outputs.full_hidden_states and outputs.attentions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test MPNetReducedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPNetReducedModel(\n",
       "  (mpnet): MPNetModel(\n",
       "    (embeddings): MPNetEmbeddings(\n",
       "      (word_embeddings): Embedding(30527, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768, padding_idx=1)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): MPNetEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x MPNetLayer(\n",
       "          (attention): MPNetAttention(\n",
       "            (attn): MPNetSelfAttention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate): MPNetIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): MPNetOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (relative_attention_bias): Embedding(32, 12)\n",
       "    )\n",
       "  )\n",
       "  (pooler): SentencePooler(pooling_mode=mean)\n",
       "  (reduce): DimReduce(\n",
       "    (0): DimReshape(\n",
       "      (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=768, out_features=512, bias=True)\n",
       "    )\n",
       "    (1): DimReshape(\n",
       "      (layernorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=512, out_features=256, bias=True)\n",
       "    )\n",
       "    (2): DimReshape(\n",
       "      (layernorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "    (3): DimReshape(\n",
       "      (layernorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=128, out_features=68, bias=True)\n",
       "    )\n",
       "    (4): DimReshape(\n",
       "      (layernorm): LayerNorm((68,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=68, out_features=48, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PASS: Module initialized without error and the structure looks correct\n",
    "config = MPNetReducedConfig()\n",
    "model = MPNetReducedModel(config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output keys: dict_keys(['last_reduced_hidden_state', 'last_full_hidden_state', 'reduced_pooler_output', 'full_pooler_output', 'reduced_hidden_states', 'full_hidden_states', 'attentions'])\n",
      "Reduced Embedding shape: torch.Size([3, 16, 48])\n",
      "Full Embedding shape: torch.Size([3, 16, 768])\n",
      "Reduced Pooled shape: torch.Size([3, 48])\n",
      "Full Pooled shape: torch.Size([3, 768])\n",
      "Intermediate Embedding shapes: [torch.Size([3, 16, 512]), torch.Size([3, 16, 256]), torch.Size([3, 16, 128]), torch.Size([3, 16, 68]), torch.Size([3, 16, 48])]\n",
      "Intermediate Pooled shapes: [torch.Size([3, 512]), torch.Size([3, 256]), torch.Size([3, 128]), torch.Size([3, 68]), torch.Size([3, 48])]\n",
      "Included hidden states and attentions: True\n"
     ]
    }
   ],
   "source": [
    "# PASS: Inputs were passed through the model, and the output shapes are as expected\n",
    "with torch.no_grad():\n",
    "    outputs = model(**mpnet_inputs)\n",
    "    print(\"Output keys:\", outputs.__dict__.keys())\n",
    "    print(\"Reduced Embedding shape:\", outputs.last_reduced_hidden_state.shape)\n",
    "    print(\"Full Embedding shape:\", outputs.last_full_hidden_state.shape)\n",
    "    print(\"Reduced Pooled shape:\", outputs.reduced_pooler_output.shape)\n",
    "    print(\"Full Pooled shape:\", outputs.full_pooler_output.shape)\n",
    "    print(\"Intermediate Embedding shapes:\", [layer.shape for layer in outputs.reduced_hidden_states[0]])\n",
    "    print(\"Intermediate Pooled shapes:\", [layer.shape for layer in outputs.reduced_hidden_states[1]])\n",
    "    print(\"Included hidden states and attentions:\", bool(outputs.full_hidden_states and outputs.attentions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test MPNetReducedForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPNetReducedForSequenceClassification(\n",
       "  (mpnet): MPNetModel(\n",
       "    (embeddings): MPNetEmbeddings(\n",
       "      (word_embeddings): Embedding(30527, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768, padding_idx=1)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): MPNetEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x MPNetLayer(\n",
       "          (attention): MPNetAttention(\n",
       "            (attn): MPNetSelfAttention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate): MPNetIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): MPNetOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (relative_attention_bias): Embedding(32, 12)\n",
       "    )\n",
       "  )\n",
       "  (pooler): SentencePooler(pooling_mode=mean)\n",
       "  (reduce): DimReduce(\n",
       "    (0): DimReshape(\n",
       "      (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=768, out_features=512, bias=True)\n",
       "    )\n",
       "    (1): DimReshape(\n",
       "      (layernorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=512, out_features=256, bias=True)\n",
       "    )\n",
       "    (2): DimReshape(\n",
       "      (layernorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "    (3): DimReshape(\n",
       "      (layernorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=128, out_features=68, bias=True)\n",
       "    )\n",
       "    (4): DimReshape(\n",
       "      (layernorm): LayerNorm((68,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=68, out_features=48, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((48,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=48, out_features=2, bias=True)\n",
       "  (seq_class_loss): SequenceClassificationLoss()\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PASS: Module initialized without error and the structure looks correct\n",
    "config = MPNetReducedConfig()\n",
    "model = MPNetReducedForSequenceClassification(config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output keys: dict_keys(['loss', 'logits', 'reduced_hidden_states', 'full_hidden_states', 'attentions'])\n",
      "Loss (Should be None): None\n",
      "Logits shape: torch.Size([3, 2])\n",
      "Intermediate Pooled shapes: [torch.Size([3, 512]), torch.Size([3, 256]), torch.Size([3, 128]), torch.Size([3, 68]), torch.Size([3, 48])]\n",
      "Included hidden states and attentions: True\n"
     ]
    }
   ],
   "source": [
    "# PASS(1/2): Inputs were passed through the model, and the output shapes are as expected\n",
    "with torch.no_grad():\n",
    "    outputs = model(**mpnet_inputs)\n",
    "    print(\"Output keys:\", outputs.__dict__.keys())\n",
    "    print(\"Loss (Should be None):\", outputs.loss)\n",
    "    print(\"Logits shape:\", outputs.logits.shape)\n",
    "    print(\"Intermediate Pooled shapes:\", [layer.shape for layer in outputs.reduced_hidden_states])\n",
    "    print(\"Included hidden states and attentions:\", bool(outputs.full_hidden_states and outputs.attentions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output keys: dict_keys(['loss', 'logits', 'reduced_hidden_states', 'full_hidden_states', 'attentions'])\n",
      "Loss: tensor(0.7776, device='cuda:0')\n",
      "Logits shape: torch.Size([3, 2])\n",
      "Intermediate Pooled shapes: [torch.Size([3, 512]), torch.Size([3, 256]), torch.Size([3, 128]), torch.Size([3, 68]), torch.Size([3, 48])]\n",
      "Included hidden states and attentions: True\n"
     ]
    }
   ],
   "source": [
    "# PASS(2/2): Loss is computed without raising an error\n",
    "with torch.no_grad():\n",
    "    outputs = model(**mpnet_inputs, labels=mpnet_labels)\n",
    "    print(\"Output keys:\", outputs.__dict__.keys())\n",
    "    print(\"Loss:\", outputs.loss)\n",
    "    print(\"Logits shape:\", outputs.logits.shape)\n",
    "    print(\"Intermediate Pooled shapes:\", [layer.shape for layer in outputs.reduced_hidden_states])\n",
    "    print(\"Included hidden states and attentions:\", bool(outputs.full_hidden_states and outputs.attentions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test MPNetCompressedModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPNetCompressedModel(\n",
       "  (mpnet): MPNetModel(\n",
       "    (embeddings): MPNetEmbeddings(\n",
       "      (word_embeddings): Embedding(30527, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768, padding_idx=1)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): MPNetEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x MPNetLayer(\n",
       "          (attention): MPNetAttention(\n",
       "            (attn): MPNetSelfAttention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate): MPNetIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): MPNetOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (relative_attention_bias): Embedding(32, 12)\n",
       "    )\n",
       "  )\n",
       "  (pooler): SentencePooler(pooling_mode=mean)\n",
       "  (reduce): DimReduce(\n",
       "    (0): DimReshape(\n",
       "      (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=768, out_features=512, bias=True)\n",
       "    )\n",
       "    (1): DimReshape(\n",
       "      (layernorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=512, out_features=256, bias=True)\n",
       "    )\n",
       "    (2): DimReshape(\n",
       "      (layernorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "    (3): DimReshape(\n",
       "      (layernorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=128, out_features=68, bias=True)\n",
       "    )\n",
       "    (4): DimReshape(\n",
       "      (layernorm): LayerNorm((68,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=68, out_features=48, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (expand): DimExpand(\n",
       "    (0): DimReshape(\n",
       "      (layernorm): LayerNorm((48,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=48, out_features=68, bias=True)\n",
       "    )\n",
       "    (1): DimReshape(\n",
       "      (layernorm): LayerNorm((68,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=68, out_features=128, bias=True)\n",
       "    )\n",
       "    (2): DimReshape(\n",
       "      (layernorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=128, out_features=256, bias=True)\n",
       "    )\n",
       "    (3): DimReshape(\n",
       "      (layernorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=256, out_features=512, bias=True)\n",
       "    )\n",
       "    (4): DimReshape(\n",
       "      (layernorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=512, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PASS: Module initialized without error and the structure looks correct\n",
    "config = MPNetReducedConfig()\n",
    "model = MPNetCompressedModel(config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output keys: dict_keys(['last_reduced_hidden_state', 'last_full_hidden_state', 'reduced_hidden_states', 'full_hidden_states', 'attentions'])\n",
      "Reduced Embedding shape: torch.Size([3, 48])\n",
      "Full Embedding shape: torch.Size([3, 768])\n",
      "Intermediate Reduced Embedding shapes: [torch.Size([3, 512]), torch.Size([3, 256]), torch.Size([3, 128]), torch.Size([3, 68]), torch.Size([3, 48])]\n",
      "Included hidden states and attentions: True\n"
     ]
    }
   ],
   "source": [
    "# PASS: Inputs were passed through the model, and the output shapes are as expected\n",
    "with torch.no_grad():\n",
    "    outputs = model(**mpnet_inputs)\n",
    "    print(\"Output keys:\", outputs.__dict__.keys())\n",
    "    print(\"Reduced Embedding shape:\", outputs.last_reduced_hidden_state.shape)\n",
    "    print(\"Full Embedding shape:\", outputs.last_full_hidden_state.shape)\n",
    "    print(\"Intermediate Reduced Embedding shapes:\", [layer.shape for layer in outputs.reduced_hidden_states])\n",
    "    print(\"Included hidden states and attentions:\", bool(outputs.full_hidden_states and outputs.attentions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test MPNetCompressedForPreTraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPNetCompressedForPreTraining(\n",
       "  (mpnet): MPNetModel(\n",
       "    (embeddings): MPNetEmbeddings(\n",
       "      (word_embeddings): Embedding(30527, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768, padding_idx=1)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): MPNetEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x MPNetLayer(\n",
       "          (attention): MPNetAttention(\n",
       "            (attn): MPNetSelfAttention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate): MPNetIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): MPNetOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (relative_attention_bias): Embedding(32, 12)\n",
       "    )\n",
       "  )\n",
       "  (pooler): SentencePooler(pooling_mode=mean)\n",
       "  (reduce): DimReduce(\n",
       "    (0): DimReshape(\n",
       "      (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=768, out_features=512, bias=True)\n",
       "    )\n",
       "    (1): DimReshape(\n",
       "      (layernorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=512, out_features=256, bias=True)\n",
       "    )\n",
       "    (2): DimReshape(\n",
       "      (layernorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "    (3): DimReshape(\n",
       "      (layernorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=128, out_features=68, bias=True)\n",
       "    )\n",
       "    (4): DimReshape(\n",
       "      (layernorm): LayerNorm((68,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=68, out_features=48, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (expand): DimExpand(\n",
       "    (0): DimReshape(\n",
       "      (layernorm): LayerNorm((48,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=48, out_features=68, bias=True)\n",
       "    )\n",
       "    (1): DimReshape(\n",
       "      (layernorm): LayerNorm((68,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=68, out_features=128, bias=True)\n",
       "    )\n",
       "    (2): DimReshape(\n",
       "      (layernorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=128, out_features=256, bias=True)\n",
       "    )\n",
       "    (3): DimReshape(\n",
       "      (layernorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=256, out_features=512, bias=True)\n",
       "    )\n",
       "    (4): DimReshape(\n",
       "      (layernorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=512, out_features=768, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (params): ParameterDict(\n",
       "      (contrastive_weight): Parameter containing: [torch.cuda.FloatTensor of size  (cuda:0)]\n",
       "      (reconstruction_weight): Parameter containing: [torch.cuda.FloatTensor of size  (cuda:0)]\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PASS(1/2): Module initialized without error and the structure looks correct\n",
    "config = MPNetReducedConfig()\n",
    "model = MPNetCompressedForPreTraining(config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At least one of do_contrast and do_reconstruction must be True\n"
     ]
    }
   ],
   "source": [
    "# PASS(2/2): Error is raised when initializing without both losses\n",
    "config = MPNetReducedConfig()\n",
    "try:\n",
    "    MPNetCompressedForPreTraining(config, do_contrast=False, do_reconstruction=False)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output keys: dict_keys(['loss', 'contrastive_loss', 'reconstruction_loss', 'reduced_hidden_states', 'reconstructed_hidden_states', 'full_hidden_states', 'attentions'])\n",
      "Total Loss: tensor(1.9267, device='cuda:0')\n",
      "Contrastive Loss: tensor(0.1961, device='cuda:0')\n",
      "Reconstruction Loss: tensor(1.7306, device='cuda:0')\n",
      "Intermediate Reduced Embedding shapes: [torch.Size([3, 512]), torch.Size([3, 256]), torch.Size([3, 128]), torch.Size([3, 68]), torch.Size([3, 48])]\n",
      "Intermediate Reconstruction shapes: [torch.Size([3, 68]), torch.Size([3, 128]), torch.Size([3, 256]), torch.Size([3, 512]), torch.Size([3, 768])]\n",
      "Included hidden states and attentions: True\n"
     ]
    }
   ],
   "source": [
    "# PASS(1/4): The full loss is computed without raising an error \n",
    "with torch.no_grad():\n",
    "    outputs = model(**mpnet_inputs)\n",
    "    print(\"Output keys:\", outputs.__dict__.keys())\n",
    "    print(\"Total Loss:\", outputs.loss)\n",
    "    print(\"Contrastive Loss:\", outputs.contrastive_loss)\n",
    "    print(\"Reconstruction Loss:\", outputs.reconstruction_loss)\n",
    "    print(\"Intermediate Reduced Embedding shapes:\", [layer.shape for layer in outputs.reduced_hidden_states])\n",
    "    print(\"Intermediate Reconstruction shapes:\", [layer.shape for layer in outputs.reconstructed_hidden_states])\n",
    "    print(\"Included hidden states and attentions:\", bool(outputs.full_hidden_states and outputs.attentions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output keys: dict_keys(['loss', 'contrastive_loss', 'reconstruction_loss', 'reduced_hidden_states', 'reconstructed_hidden_states', 'full_hidden_states', 'attentions'])\n",
      "Total Loss: tensor(0.2221, device='cuda:0')\n",
      "Contrastive Loss: tensor(0.2221, device='cuda:0')\n",
      "Reconstruction Loss (None): None\n",
      "Intermediate Reduced Embedding shapes: [torch.Size([3, 512]), torch.Size([3, 256]), torch.Size([3, 128]), torch.Size([3, 68]), torch.Size([3, 48])]\n",
      "Intermediate Reconstruction shapes (None): None\n",
      "Included hidden states and attentions: True\n"
     ]
    }
   ],
   "source": [
    "# PASS(2/4): The contrastive loss is computed alone without raising an error\n",
    "#            Total loss matches the contrastive loss, reconstruction loss is None\n",
    "with torch.no_grad():\n",
    "    model.do_contrast = True\n",
    "    model.do_reconstruction = False\n",
    "    outputs = model(**mpnet_inputs)\n",
    "    print(\"Output keys:\", outputs.__dict__.keys())\n",
    "    print(\"Total Loss:\", outputs.loss)\n",
    "    print(\"Contrastive Loss:\", outputs.contrastive_loss)\n",
    "    print(\"Reconstruction Loss (None):\", outputs.reconstruction_loss)\n",
    "    print(\"Intermediate Reduced Embedding shapes:\", [layer.shape for layer in outputs.reduced_hidden_states])\n",
    "    print(\"Intermediate Reconstruction shapes (None):\", outputs.reconstructed_hidden_states)\n",
    "    print(\"Included hidden states and attentions:\", bool(outputs.full_hidden_states and outputs.attentions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output keys: dict_keys(['loss', 'contrastive_loss', 'reconstruction_loss', 'reduced_hidden_states', 'reconstructed_hidden_states', 'full_hidden_states', 'attentions'])\n",
      "Total Loss: tensor(1.7378, device='cuda:0')\n",
      "Contrastive Loss (None): None\n",
      "Reconstruction Loss: tensor(1.7378, device='cuda:0')\n",
      "Intermediate Reduced Embedding shapes: [torch.Size([3, 512]), torch.Size([3, 256]), torch.Size([3, 128]), torch.Size([3, 68]), torch.Size([3, 48])]\n",
      "Intermediate Reconstruction shapes: [torch.Size([3, 68]), torch.Size([3, 128]), torch.Size([3, 256]), torch.Size([3, 512]), torch.Size([3, 768])]\n",
      "Included hidden states and attentions: True\n"
     ]
    }
   ],
   "source": [
    "# PASS(3/4): The reconstruction loss is computed alone without raising an error\n",
    "#            Total loss matches the reconstruction loss, contrastive loss is None\n",
    "with torch.no_grad():\n",
    "    model.do_contrast = False\n",
    "    model.do_reconstruction = True\n",
    "    outputs = model(**mpnet_inputs)\n",
    "    print(\"Output keys:\", outputs.__dict__.keys())\n",
    "    print(\"Total Loss:\", outputs.loss)\n",
    "    print(\"Contrastive Loss (None):\", outputs.contrastive_loss)\n",
    "    print(\"Reconstruction Loss:\", outputs.reconstruction_loss)\n",
    "    print(\"Intermediate Reduced Embedding shapes:\", [layer.shape for layer in outputs.reduced_hidden_states])\n",
    "    print(\"Intermediate Reconstruction shapes:\", [layer.shape for layer in outputs.reconstructed_hidden_states])\n",
    "    print(\"Included hidden states and attentions:\", bool(outputs.full_hidden_states and outputs.attentions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output keys: dict_keys(['loss', 'contrastive_loss', 'reconstruction_loss', 'reduced_hidden_states', 'reconstructed_hidden_states', 'full_hidden_states', 'attentions'])\n",
      "Total Loss: tensor(0.4758, device='cuda:0')\n",
      "Contrastive Loss (None): tensor(0.0037, device='cuda:0')\n",
      "Reconstruction Loss: tensor(0.4721, device='cuda:0')\n",
      "Intermediate Reduced Embedding shapes: [torch.Size([3, 512]), torch.Size([3, 256]), torch.Size([3, 128]), torch.Size([3, 68]), torch.Size([3, 48])]\n",
      "Intermediate Reconstruction shapes: [torch.Size([3, 68]), torch.Size([3, 128]), torch.Size([3, 256]), torch.Size([3, 512]), torch.Size([3, 768])]\n",
      "Included hidden states and attentions: True\n"
     ]
    }
   ],
   "source": [
    "# PASS(4/4): Compute the total, not full loss without raising an error\n",
    "with torch.no_grad():\n",
    "    model.do_contrast = True\n",
    "    model.do_reconstruction = True\n",
    "    outputs = model(**mpnet_inputs, compute_full_loss=False)\n",
    "    print(\"Output keys:\", outputs.__dict__.keys())\n",
    "    print(\"Total Loss:\", outputs.loss)\n",
    "    print(\"Contrastive Loss (None):\", outputs.contrastive_loss)\n",
    "    print(\"Reconstruction Loss:\", outputs.reconstruction_loss)\n",
    "    print(\"Intermediate Reduced Embedding shapes:\", [layer.shape for layer in outputs.reduced_hidden_states])\n",
    "    print(\"Intermediate Reconstruction shapes:\", [layer.shape for layer in outputs.reconstructed_hidden_states])\n",
    "    print(\"Included hidden states and attentions:\", bool(outputs.full_hidden_states and outputs.attentions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test MPNetCompressedForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPNetCompressedForSequenceClassification(\n",
       "  (mpnet): MPNetModel(\n",
       "    (embeddings): MPNetEmbeddings(\n",
       "      (word_embeddings): Embedding(30527, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768, padding_idx=1)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): MPNetEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x MPNetLayer(\n",
       "          (attention): MPNetAttention(\n",
       "            (attn): MPNetSelfAttention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (intermediate): MPNetIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): MPNetOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (relative_attention_bias): Embedding(32, 12)\n",
       "    )\n",
       "  )\n",
       "  (pooler): SentencePooler(pooling_mode=mean)\n",
       "  (reduce): DimReduce(\n",
       "    (0): DimReshape(\n",
       "      (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=768, out_features=512, bias=True)\n",
       "    )\n",
       "    (1): DimReshape(\n",
       "      (layernorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=512, out_features=256, bias=True)\n",
       "    )\n",
       "    (2): DimReshape(\n",
       "      (layernorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "    (3): DimReshape(\n",
       "      (layernorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=128, out_features=68, bias=True)\n",
       "    )\n",
       "    (4): DimReshape(\n",
       "      (layernorm): LayerNorm((68,), eps=1e-12, elementwise_affine=True)\n",
       "      (activation): GELUActivation()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (dense): Linear(in_features=68, out_features=48, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((48,), eps=1e-12, elementwise_affine=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=48, out_features=2, bias=True)\n",
       "  (seq_class_loss): SequenceClassificationLoss()\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PASS: Module initialized without error and the structure looks correct \n",
    "config = MPNetReducedConfig()\n",
    "model = MPNetCompressedForSequenceClassification(config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output keys: dict_keys(['loss', 'logits', 'reduced_hidden_states', 'full_hidden_states', 'attentions'])\n",
      "Loss (Should be None): None\n",
      "Logits shape: torch.Size([3, 2])\n",
      "Intermediate Pooled shapes: [torch.Size([3, 512]), torch.Size([3, 256]), torch.Size([3, 128]), torch.Size([3, 68]), torch.Size([3, 48])]\n",
      "Included hidden states and attentions: True\n"
     ]
    }
   ],
   "source": [
    "# PASS(1/2): Inputs were passed through the model, and the output shapes are as expected\n",
    "with torch.no_grad():\n",
    "    outputs = model(**mpnet_inputs)\n",
    "    print(\"Output keys:\", outputs.__dict__.keys())\n",
    "    print(\"Loss (Should be None):\", outputs.loss)\n",
    "    print(\"Logits shape:\", outputs.logits.shape)\n",
    "    print(\"Intermediate Pooled shapes:\", [layer.shape for layer in outputs.reduced_hidden_states])\n",
    "    print(\"Included hidden states and attentions:\", bool(outputs.full_hidden_states and outputs.attentions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output keys: dict_keys(['loss', 'logits', 'reduced_hidden_states', 'full_hidden_states', 'attentions'])\n",
      "Loss: tensor(0.8921, device='cuda:0')\n",
      "Logits shape: torch.Size([3, 2])\n",
      "Intermediate Pooled shapes: [torch.Size([3, 512]), torch.Size([3, 256]), torch.Size([3, 128]), torch.Size([3, 68]), torch.Size([3, 48])]\n",
      "Included hidden states and attentions: True\n"
     ]
    }
   ],
   "source": [
    "# PASS(2/2): Loss is computed without raising an error\n",
    "with torch.no_grad():\n",
    "    outputs = model(**mpnet_inputs, labels=mpnet_labels)\n",
    "    print(\"Output keys:\", outputs.__dict__.keys())\n",
    "    print(\"Loss:\", outputs.loss)\n",
    "    print(\"Logits shape:\", outputs.logits.shape)\n",
    "    print(\"Intermediate Pooled shapes:\", [layer.shape for layer in outputs.reduced_hidden_states])\n",
    "    print(\"Included hidden states and attentions:\", bool(outputs.full_hidden_states and outputs.attentions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reduced_encoders",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "set_seed(916)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8ae24038b84e8092ac8ee4b238f945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e63782093fd4c68835681fc1e0d8db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sbert_reduced import SBertReduce\n",
    "from sentence_transformers import models, SentenceTransformer, InputExample, losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def load_sbert_reduced(reduced_size=48, inter_sizes=(512,256,128,64)):\n",
    "    word_embedding_model = models.Transformer(\"bert-base-uncased\", max_seq_length=512)\n",
    "    embedding_reduction_model = SBertReduce(word_embedding_model.get_word_embedding_dimension(), reduced_size, inter_sizes)\n",
    "    pooling_model = models.Pooling(reduced_size)\n",
    "    return SentenceTransformer(modules=[word_embedding_model, embedding_reduction_model, pooling_model])\n",
    "\n",
    "model = load_sbert_reduced()\n",
    " \n",
    "train_examples = [InputExample(texts=[\"This is a sentence\", \"This is also a sentence\"], label=0.8),\n",
    "                  InputExample(texts=[\"One sentence\", \"Another sentence\"], label=0.3)]\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=1, warmup_steps=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"stsb-sbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stsb-sbert/1_SBertReduce\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'stsb-sbert/1_SBertReduce/config.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m SBertReduce\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39mstsb-sbert\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/ReducedBertModel/bert_reduced.py:318\u001b[0m, in \u001b[0;36mSBertReduce.load\u001b[0;34m(input_path)\u001b[0m\n\u001b[1;32m    316\u001b[0m layers \u001b[39m=\u001b[39m []\n\u001b[1;32m    317\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m4\u001b[39m):\n\u001b[0;32m--> 318\u001b[0m     layers\u001b[39m.\u001b[39mappend(SBertReductionLayer\u001b[39m.\u001b[39;49mload(input_path))\n\u001b[1;32m    319\u001b[0m \u001b[39mreturn\u001b[39;00m SBertReduce(layers)\n",
      "File \u001b[0;32m~/ReducedBertModel/bert_reduced.py:373\u001b[0m, in \u001b[0;36mSBertReductionLayer.load\u001b[0;34m(input_path)\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    371\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(input_path):\n\u001b[1;32m    372\u001b[0m     \u001b[39mprint\u001b[39m(input_path)\n\u001b[0;32m--> 373\u001b[0m     dense \u001b[39m=\u001b[39m Dense\u001b[39m.\u001b[39;49mload(input_path)\n\u001b[1;32m    374\u001b[0m     dropout \u001b[39m=\u001b[39m Dropout\u001b[39m.\u001b[39mload(input_path)\n\u001b[1;32m    375\u001b[0m     \u001b[39mreturn\u001b[39;00m SBertReductionLayer(dense, dropout)\n",
      "File \u001b[0;32m~/ReducedBertModel/.venv/lib/python3.10/site-packages/sentence_transformers/models/Dense.py:58\u001b[0m, in \u001b[0;36mDense.load\u001b[0;34m(input_path)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(input_path):\n\u001b[0;32m---> 58\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(input_path, \u001b[39m'\u001b[39;49m\u001b[39mconfig.json\u001b[39;49m\u001b[39m'\u001b[39;49m)) \u001b[39mas\u001b[39;00m fIn:\n\u001b[1;32m     59\u001b[0m         config \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(fIn)\n\u001b[1;32m     61\u001b[0m     config[\u001b[39m'\u001b[39m\u001b[39mactivation_function\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m import_from_string(config[\u001b[39m'\u001b[39m\u001b[39mactivation_function\u001b[39m\u001b[39m'\u001b[39m])()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'stsb-sbert/1_SBertReduce/config.json'"
     ]
    }
   ],
   "source": [
    "SBertReduce.load(\"stsb-sbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_reduced.bert_reduced import BertReducedForPreTraining, SBertReduce\n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "\n",
    "def load_sbert(model_name, revision=\"main\"):\n",
    "    pretrained = BertReducedForPreTraining.from_pretrained(model_name, revision=revision)\n",
    "\n",
    "    word_embedding_model = models.Transformer(\"bert-base-uncased\", max_seq_length=pretrained.config.max_position_embeddings)\n",
    "    embedding_reduction_model = SBertReduce(pretrained.reduce)\n",
    "    pooling_model = models.Pooling(pretrained.config.reduced_size)\n",
    "\n",
    "    return SentenceTransformer(modules=[word_embedding_model, embedding_reduction_model, pooling_model])\n",
    "\n",
    "sbert_model = load_sbert(\"cayjobla/bert-base-uncased-reduced\", revision=\"pretrain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_reduced.bert_reduced import BertReducedForPreTraining, SBertReduce\n",
    "from sentence_transformers import SentenceTransformer, models\n",
    "\n",
    "word_embedding_model = models.Transformer(\"bert-base-uncased\", max_seq_length=512)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "model.save('stsb-sbert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STS Benchmark dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset stsb_multi_mt (/home/cayjobla/.cache/huggingface/datasets/stsb_multi_mt/en/1.0.0/a5d260e4b7aa82d1ab7379523a005a366d9b124c76a5a5cf0c4c5365458b0ba9)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f34b088f040405a899aec78f42ed142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'similarity_score'],\n",
       "        num_rows: 5749\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'similarity_score'],\n",
       "        num_rows: 1379\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'similarity_score'],\n",
       "        num_rows: 1500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"stsb_multi_mt\", \"en\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What I need to do still:\n",
    "* Data labels need to be adjusted to be between 0 and 1\n",
    "* In our data, 5 indicates very similar. Does the CosineSimilarity relate larger or smaller numbers with similarity? Do I need to adjust?\n",
    "* Adjust model to make it loadable later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import InputExample\n",
    "\n",
    "def wrap_data(examples):\n",
    "    return [InputExample(texts=[examples[\"sentence1\"][i], examples[\"sentence2\"][i]], \n",
    "                         label=examples[\"similarity_score\"][i]) for i in range(len(examples))]\n",
    "\n",
    "training_data = wrap_data(raw_datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afcbcbd9c92c4193837d366fcfa9b727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8f8ea6298a44a2819e501efd287adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79fede371b7f4ad89a985e87695b2176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e221c3d30e74493f8e96077997ab48c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10772eb5a94e4c8d9fc65df394ebb117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe83e5f23814e8d9b4077f7c2f874fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea392b9620c947b68e25df77a7b59bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456bf56d0bef478d92c0056ef5046c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e3453d5fbf043e78df6da098cdb45f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a627a9995e548bbabfbffc5976f5132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be960fecdfda471483dc49d139a9bdd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'SBertReduce' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m train_dataloader \u001b[39m=\u001b[39m DataLoader(training_data, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, batch_size\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m)\n\u001b[1;32m      5\u001b[0m train_loss \u001b[39m=\u001b[39m losses\u001b[39m.\u001b[39mCosineSimilarityLoss(sbert_model)\n\u001b[0;32m----> 7\u001b[0m sbert_model\u001b[39m.\u001b[39;49mfit(train_objectives\u001b[39m=\u001b[39;49m[(train_dataloader, train_loss)], epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, warmup_steps\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, evaluation_steps\u001b[39m=\u001b[39;49m\u001b[39m360\u001b[39;49m, output_path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mstsb-sbert\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/ReducedBertModel/.venv/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:748\u001b[0m, in \u001b[0;36mSentenceTransformer.fit\u001b[0;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, show_progress_bar, checkpoint_path, checkpoint_save_steps, checkpoint_save_total_limit)\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_during_training(evaluator, output_path, save_best_model, epoch, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, callback)\n\u001b[1;32m    747\u001b[0m \u001b[39mif\u001b[39;00m evaluator \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m output_path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:   \u001b[39m#No evaluator, but output path: save final model version\u001b[39;00m\n\u001b[0;32m--> 748\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave(output_path)\n\u001b[1;32m    750\u001b[0m \u001b[39mif\u001b[39;00m checkpoint_path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    751\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_checkpoint(checkpoint_path, checkpoint_save_total_limit, global_step)\n",
      "File \u001b[0;32m~/ReducedBertModel/.venv/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:375\u001b[0m, in \u001b[0;36mSentenceTransformer.save\u001b[0;34m(self, path, model_name, create_model_card, train_datasets)\u001b[0m\n\u001b[1;32m    372\u001b[0m         model_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, \u001b[39mstr\u001b[39m(idx)\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mtype\u001b[39m(module)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    374\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(model_path, exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 375\u001b[0m     module\u001b[39m.\u001b[39;49msave(model_path)\n\u001b[1;32m    376\u001b[0m     modules_config\u001b[39m.\u001b[39mappend({\u001b[39m'\u001b[39m\u001b[39midx\u001b[39m\u001b[39m'\u001b[39m: idx, \u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m: name, \u001b[39m'\u001b[39m\u001b[39mpath\u001b[39m\u001b[39m'\u001b[39m: os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(model_path), \u001b[39m'\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mtype\u001b[39m(module)\u001b[39m.\u001b[39m\u001b[39m__module__\u001b[39m})\n\u001b[1;32m    378\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, \u001b[39m'\u001b[39m\u001b[39mmodules.json\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m fOut:\n",
      "File \u001b[0;32m~/ReducedBertModel/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SBertReduce' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import losses\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(training_data, shuffle=True, batch_size=16)\n",
    "train_loss = losses.CosineSimilarityLoss(sbert_model)\n",
    "\n",
    "sbert_model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=10, warmup_steps=0, evaluation_steps=360, output_path=\"stsb-sbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

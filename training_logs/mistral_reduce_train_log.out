[rank2]:[W326 20:46:26.663909852 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
[rank1]:[W326 20:46:26.670903437 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:09<00:19,  9.97s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:20<00:10, 10.37s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:29<00:00,  9.69s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:29<00:00,  9.83s/it]
[rank0]:[W326 20:46:57.766458206 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:07<00:15,  7.58s/it]Loading checkpoint shards:  33%|███▎      | 1/3 [00:07<00:15,  7.56s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:15<00:07,  7.90s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:15<00:07,  7.90s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:22<00:00,  7.49s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:22<00:00,  7.57s/it]
Loading checkpoint shards: 100%|██████████| 3/3 [00:22<00:00,  7.52s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:22<00:00,  7.59s/it]
Loaded model: Linq-AI-Research/Linq-Embed-Mistral
Initialized reduction and expansion layers with sizes: [4096, 3584, 2048, 1536, 1024, 768, 512, 384, 256, 128, 64]
Loaded medi dataset: /home/cayjobla/ReducedEncoders/medi-data/medi-data.json, eval size: 8000
Initialized DimensionalReductionLoss with weights: tensor([0.5000, 0.5000])
Initialized optimizer and LR scheduler
wandb: Currently logged in as: cayjobla. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.0
wandb: Run data is saved locally in /home/cayjobla/ReducedEncoders/wandb/run-20250326_204831-v8awigjy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mistral-reduced
wandb: ⭐️ View project at https://wandb.ai/cayjobla/reduced-encoders
wandb: 🚀 View run at https://wandb.ai/cayjobla/reduced-encoders/runs/v8awigjy
Initialized wandb tracking with run name: mistral-reduced
Starting training loop...
Running evaluation (step 0)...
Epoch: 0.0, Step: 0, Eval Loss: 2.9758574962615967
Epoch: 0.0, Step: 0, Train Loss: 2.9520490169525146
